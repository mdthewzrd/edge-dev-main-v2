/**
 * COMPREHENSIVE AI FORMATTING PROMPTING SYSTEM
 *
 * Two-tier prompting system:
 * 1. MASTER_FORMATTING_PROMPT - Quick 2-stage transformation (for known scanner types)
 * 2. MASTER_STANDARDIZATION_REFERENCE - Detailed structure reference (for unknown/custom scanners)
 */

// ===== MASTER FORMATTING PROMPTS =====

export const MASTER_FORMATTING_PROMPT = `Transform the following Python code into a PRODUCTION-GRADE 3-stage trading scanner architecture.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     CRITICAL: PRODUCTION-GRADE ARCHITECTURE WITH PERFORMANCE OPTIMIZATION        â•‘
â•‘              Target: <10 minutes for full year scan (47 signals expected)        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš¨ MANDATORY REQUIREMENTS - VIOLATION WILL CAUSE BUGS ğŸš¨

1. INITIALIZATION ORDER (CRITICAL - Prevents NameError):
   =======================================================
   class ScannerName:
       def __init__(self, api_key, d0_start, d0_end):
           # âš ï¸ DEFINE PARAMETERS FIRST - Before any calculations!
           self.params = {
               "price_min": 8.0,
               "adv20_min_usd": 30_000_000,
               # ... ALL parameters must be defined here
           }

           # NOW you can use self.params in calculations
           lookback_buffer = self.params['abs_lookback_days'] + 50

2. COMPUTE_ALL_FEATURES METHOD - CRITICAL COLUMN DEPENDENCIES:
   ================================================================
   def compute_full_features(self, df):
       # âš ï¸ Compute ALL columns that will be referenced later!
       df = df.sort_values(['ticker', 'date']).reset_index(drop=True)

       # EMAs
       df['EMA_9'] = df.groupby('ticker')['close'].ewm(span=9, adjust=False).mean().reset_index(0, drop=True)
       df['EMA_20'] = df.groupby('ticker')['close'].ewm(span=20, adjust=False).mean().reset_index(0, drop=True)

       # ATR
       df['tr'] = np.maximum(
           df['high'] - df['low'],
           np.abs(df['high'] - df.groupby('ticker')['close'].shift(1)),
           np.abs(df['low'] - df.groupby('ticker')['close'].shift(1))
       )
       df['ATR_raw'] = df.groupby('ticker')['tr'].rolling(14, min_periods=14).mean().reset_index(0, drop=True)
       df['ATR'] = df.groupby('ticker')['ATR_raw'].shift(1)

       # Volume metrics
       df['VOL_AVG'] = df.groupby('ticker')['volume'].rolling(14, min_periods=14).mean().reset_index(0, drop=True).shift(1)
       df['Prev_Volume'] = df.groupby('ticker')['volume'].shift(1)  # âš ï¸ REQUIRED for trigger checks!

       # Slopes
       df['Slope_9_5d'] = (df['EMA_9'] - df.groupby('ticker')['EMA_9'].shift(5)) / df.groupby('ticker')['EMA_9'].shift(5) * 100

       # âš ï¸ CRITICAL: High_over_EMA9_div_ATR - REQUIRED for trigger checks!
       df['High_over_EMA9_div_ATR'] = (df['high'] - df['EMA_9']) / df['ATR']

       # Gap metrics
       df['Gap_abs'] = (df['open'] - df.groupby('ticker')['close'].shift(1)).abs()
       df['Gap_over_ATR'] = df['Gap_abs'] / df['ATR']

       # Other metrics
       df['Open_over_EMA9'] = df['open'] / df['EMA_9']
       df['Body_over_ATR'] = (df['close'] - df['open']).abs() / df['ATR']

       # âš ï¸ CRITICAL: Prev_* columns - REQUIRED for D-1 > D-2 comparisons!
       df['Prev_Close'] = df.groupby('ticker')['close'].shift(1)
       df['Prev_Open'] = df.groupby('ticker')['open'].shift(1)
       df['Prev_High'] = df.groupby('ticker')['high'].shift(1)
       df['Prev_Low'] = df.groupby('ticker')['low'].shift(1)

       return df

3. PATTERN DETECTION - VECTORIZED OPERATIONS (Performance Critical):
   ================================================================
   def detect_patterns(self, df):
       # âš ï¸ Convert date column ONCE - Not in loops!
       df['date'] = pd.to_datetime(df['date'])
       d0_start_dt = pd.to_datetime(self.d0_start)
       d0_end_dt = pd.to_datetime(self.d0_end)

       ticker_data_list = []
       for ticker in df['ticker'].unique():
           ticker_df = df[df['ticker'] == ticker].copy()
           ticker_data_list.append((ticker, ticker_df, d0_start_dt, d0_end_dt))

       # Parallel processing
       with ThreadPoolExecutor(max_workers=self.stage3_workers) as executor:
           futures = [executor.submit(self._process_ticker, ticker_data) for ticker_data in ticker_data_list]
           results_list = [future.result() for future in as_completed(futures) if future.result()]

       return pd.concat(results_list, ignore_index=True) if results_list else pd.DataFrame()

4. PROCESS_TICKER - VECTORIZED FILTERING (10x Performance Boost):
   ================================================================
   def _process_ticker(self, ticker_data):
       ticker, ticker_df, d0_start_dt, d0_end_dt = ticker_data

       if len(ticker_df) < 100:
           return pd.DataFrame()

       ticker_df = ticker_df.sort_values('date').reset_index(drop=True)
       # âš ï¸ Already converted to datetime in detect_patterns()

       signals = []
       for i in range(2, len(ticker_df)):
           r0 = ticker_df.iloc[i]
           r1 = ticker_df.iloc[i-1]
           r2 = ticker_df.iloc[i-2]
           d0 = r0['date']

           # âš ï¸ Use datetime comparison (NOT string comparison!)
           if d0 < d0_start_dt or d0 > d0_end_dt:
               continue

           # âš ï¸ VECTORIZED ABS window calculation (NOT a function call!)
           cutoff = d0 - pd.Timedelta(days=self.params['abs_exclude_days'])
           wstart = cutoff - pd.Timedelta(days=self.params['abs_lookback_days'])

           # Vectorized filtering - 10x faster than function call
           mask = (ticker_df['date'] > wstart) & (ticker_df['date'] <= cutoff)
           win = ticker_df.loc[mask]

           if win.empty or len(win) < 2:
               continue

           lo_abs = win['low'].min()
           hi_abs = win['high'].max()

           if hi_abs <= lo_abs:
               continue

           # Position calculation
           pos_abs_prev = (r1['close'] - lo_abs) / (hi_abs - lo_abs)
           if not (0 <= pos_abs_prev <= self.params['pos_abs_max']):
               continue

           # Trigger checks
           if not self._check_trigger(r1):
               if self.params['trigger_mode'] != "D1_only" and self._check_trigger(r2):
                   pass  # D-2 trigger
               else:
                   continue

           # âš ï¸ Use Prev_High for D-1 > D-2 comparisons (NOT current 'high'!)
           if self.params['enforce_d1_above_d2']:
               if not (pd.notna(r1['Prev_High']) and pd.notna(r2['Prev_High']) and
                       r1['Prev_High'] > r2['Prev_High'] and
                       pd.notna(r1['Prev_Close']) and pd.notna(r2['Prev_Close']) and
                       r1['Prev_Close'] > r2['Prev_Close']):
                   continue

           # More checks...
           # Build signal dictionary

           # âš ï¸ Format date as string (NOT datetime object!)
           signals.append({
               "Ticker": r0['ticker'],
               "Date": d0.strftime('%Y-%m-%d'),  # String format
               # ... other fields
           })

       return pd.DataFrame(signals)

5. COLUMN REFERENCE CHECKLIST (Prevent KeyError):
   ============================================
   Before referencing a column in checks, ensure it's computed:
   âœ… Prev_Close â†’ Computed in compute_full_features()
   âœ… Prev_High â†’ Computed in compute_full_features()
   âœ… Prev_Volume â†’ Computed in compute_full_features()
   âœ… High_over_EMA9_div_ATR â†’ Computed in compute_full_features()
   âœ… VOL_AVG â†’ Computed in compute_full_features()
   âœ… ATR â†’ Computed in compute_full_features()

6. PERFORMANCE TARGETS:
   =====================
   - Full year scan: <10 minutes (target ~600 seconds)
   - 1 month scan: <3 minutes
   - 1 week scan: <1 minute

   âš ï¸ If your code is slower, you're doing something wrong!

Extract ALL parameters from input code. Preserve exact values and parameter names.

Output Python code only. Start with import statements. Use exact method names.`;

// ===== MASTER STANDARDIZATION REFERENCE =====

export const MASTER_STANDARDIZATION_REFERENCE = `
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           GROUPED ENDPOINT ARCHITECTURE - MANDATORY FOR ALL SCANNERS              â•‘
â•‘                  Reference Templates: 7 production scanners (700-900 lines)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš¨ CRITICAL: ALL SCANNERS MUST USE GROUPED ENDPOINT ARCHITECTURE
=============================================================

Reference Templates (DO NOT DEVIATE):
- /projects/edge-dev-exact/templates/backside_b/fixed_formatted.py (716 lines)
- /projects/edge-dev-exact/templates/a_plus_para/fixed_formatted.py (639 lines)
- /projects/edge-dev-exact/templates/lc_d2/fixed_formatted.py (887 lines)
- /projects/edge-dev-exact/templates/lc_3d_gap/fixed_formatted.py (713 lines)
- /projects/edge-dev-exact/templates/d1_gap/fixed_formatted.py (716 lines)
- /projects/edge-dev-exact/templates/extended_gap/fixed_formatted.py (710 lines)
- /projects/edge-dev-exact/templates/sc_dmr/fixed_formatted.py (799 lines)

âš ï¸  FORBIDDEN: Do NOT use snapshot endpoint (/v2/snapshot/.../tickers)
âœ…  REQUIRED: Use grouped endpoint (/v2/aggs/grouped/locale/us/market/stocks/{date})

Performance Comparison:
- Grouped Endpoint: 456 API calls, 60-120 seconds
- Snapshot Endpoint: 12,000+ API calls, 10+ minutes
- Efficiency: 96% reduction in API calls

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. MANDATORY IMPORTS                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  import pandas as pd                                                           â”‚
â”‚  import numpy as np                                                            â”‚
â”‚  import requests                                                               â”‚
â”‚  import time                                                                   â”‚
â”‚  from datetime import datetime, timedelta                                     â”‚
â”‚  from concurrent.futures import ThreadPoolExecutor, as_completed              â”‚
â”‚  import pandas_market_calendars as mcal  # CRITICAL: NYSE calendar            â”‚
â”‚  from typing import List, Dict, Optional, Tuple                               â”‚
â”‚  from requests.adapters import HTTPAdapter                                    â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. CLASS STRUCTURE - GROUPED ENDPOINT SCANNER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  class GroupedEndpoint{ScannerName}Scanner:                                   â”‚
â”‚      """                                                                       â”‚
â”‚      {SCANNER_NAME} USING GROUPED ENDPOINT ARCHITECTURE                      â”‚
â”‚      ==============================================                          â”‚
â”‚                                                                                â”‚
â”‚      {PATTERN_DESCRIPTION}                                                    â”‚
â”‚                                                                                â”‚
â”‚      Architecture:                                                           â”‚
â”‚      -----------                                                              â”‚
â”‚      Stage 1: Fetch grouped data (all tickers for all dates)                 â”‚
â”‚          - Uses Polygon grouped endpoint                                      â”‚
â”‚          - 1 API call per trading day (not per ticker)                       â”‚
â”‚          - Returns all tickers that traded each day                          â”‚
â”‚                                                                                â”‚
â”‚      Stage 2: Compute simple features / Apply smart filters                   â”‚
â”‚          - Price, volume, ADV filters                                         â”‚
â”‚          - Reduces dataset by ~99%                                            â”‚
â”‚                                                                                â”‚
â”‚      Stage 3: Compute full parameters + scan patterns                        â”‚
â”‚          - EMA, ATR, slopes, volume metrics                                   â”‚
â”‚          - Pattern-specific detection logic                                   â”‚
â”‚      """                                                                       â”‚
â”‚                                                                                â”‚
â”‚      def __init__(                                                              â”‚
â”‚          self,                                                                â”‚
â”‚          api_key: str = "Fm7brz4s23eSocDErnL68cE7wspz2K1I",                     â”‚
â”‚          d0_start: str = None,                                                â”‚
â”‚          d0_end: str = None                                                   â”‚
â”‚      ):                                                                         â”‚
â”‚          # ============================================================         â”‚
â”‚          #  ğŸ“… DATE RANGE CONFIGURATION                                      â”‚
â”‚          # ============================================================         â”‚
â”‚          self.DEFAULT_D0_START = "2025-01-01"                                 â”‚
â”‚          self.DEFAULT_D0_END = "2025-12-31"                                   â”‚
â”‚                                                                                â”‚
â”‚          # ============================================================         â”‚
â”‚          #  HTTP SESSION SETUP - Connection pooling                          â”‚
â”‚          # ============================================================         â”‚
â”‚          self.session = requests.Session()                                    â”‚
â”‚          self.session.mount('https://', requests.adapters.HTTPAdapter(       â”‚
â”‚              pool_connections=100,                                            â”‚
â”‚              pool_maxsize=100,                                                â”‚
â”‚              max_retries=2,                                                   â”‚
â”‚              pool_block=False                                                 â”‚
â”‚          ))                                                                     â”‚
â”‚                                                                                â”‚
â”‚          self.api_key = api_key                                                â”‚
â”‚          self.base_url = "https://api.polygon.io"                             â”‚
â”‚                                                                                â”‚
â”‚          # ============================================================         â”‚
â”‚          #  NYSE CALENDAR - CRITICAL for trading days                         â”‚
â”‚          # ============================================================         â”‚
â”‚          self.us_calendar = mcal.get_calendar('NYSE')                          â”‚
â”‚                                                                                â”‚
â”‚          # ============================================================         â”‚
â”‚          #  DATE RANGE CALCULATION                                           â”‚
â”‚          # ============================================================         â”‚
â”‚          self.d0_start = d0_start or self.DEFAULT_D0_START                    â”‚
â”‚          self.d0_end = d0_end or self.DEFAULT_D0_END                          â”‚
â”‚          lookback_days = {LOOKBACK_DAYS}  # From parameters                   â”‚
â”‚          scan_start = (pd.to_datetime(self.d0_start) -                        â”‚
â”‚                       pd.Timedelta(days=lookback_days))                       â”‚
â”‚          self.scan_start = scan_start.strftime('%Y-%m-%d')                     â”‚
â”‚          self.scan_end = self.d0_end                                           â”‚
â”‚                                                                                â”‚
â”‚          # ============================================================         â”‚
â”‚          #  WORKER CONFIGURATION                                              â”‚
â”‚          # ============================================================         â”‚
â”‚          self.stage1_workers = 5    # Parallel grouped data fetching          â”‚
â”‚          self.stage3_workers = 10   # Parallel pattern detection             â”‚
â”‚          self.batch_size = 200                                                   â”‚
â”‚                                                                                â”‚
â”‚          print(f"ğŸš€ GROUPED ENDPOINT MODE: {SCANNER_NAME} Scanner")            â”‚
â”‚          print(f"ğŸ“… Signal Output Range (D0): {self.d0_start} to {self.d0_end}")â”‚
â”‚          print(f"ğŸ“Š Historical Data Range: {self.scan_start} to {self.scan_end}")â”‚
â”‚          print(f"âš¡ Workers: Stage1={self.stage1_workers}, Stage3={self.stage3_workers}")â”‚
â”‚                                                                                â”‚
â”‚          # ============================================================         â”‚
â”‚          #  USER PARAMETERS - Preserved EXACTLY                              â”‚
â”‚          # ============================================================         â”‚
â”‚          self.params = {                                                         â”‚
â”‚              # Extract ALL parameters from user code with exact values        â”‚
â”‚          }                                                                       â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. STAGE 1: FETCH GROUPED DATA (MANDATORY)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  def get_trading_dates(self, start_date: str, end_date: str) -> List[str]:   â”‚
â”‚      """Get NYSE trading days using pandas_market_calendars"""                â”‚
â”‚      schedule = self.us_calendar.schedule(                                     â”‚
â”‚          start_date=pd.to_datetime(start_date),                               â”‚
â”‚          end_date=pd.to_datetime(end_date)                                    â”‚
â”‚      )                                                                         â”‚
â”‚      trading_days = self.us_calendar.valid_days(                              â”‚
â”‚          start_date=pd.to_datetime(start_date),                               â”‚
â”‚          end_date=pd.to_datetime(end_date)                                    â”‚
â”‚      )                                                                         â”‚
â”‚      return [date.strftime('%Y-%m-%d') for date in trading_days]              â”‚
â”‚                                                                                â”‚
â”‚  def fetch_all_grouped_data(self, trading_dates: List[str]) -> pd.DataFrame:  â”‚
â”‚      """                                                                       â”‚
â”‚      Stage 1: Fetch ALL data for ALL tickers using grouped endpoint          â”‚
â”‚      ONE API call per trading day - MUCH MORE EFFICIENT                      â”‚
â”‚      """                                                                       â”‚
â”‚      print(f"\\n{'='*70}")                                                    â”‚
â”‚      print("ğŸš€ STAGE 1: FETCH GROUPED DATA")                                  â”‚
â”‚      print(f"{'='*70}")                                                      â”‚
â”‚      print(f"ğŸ“¡ Fetching {len(trading_dates)} trading days...")                â”‚
â”‚                                                                                â”‚
â”‚      all_data = []                                                             â”‚
â”‚      completed = 0                                                             â”‚
â”‚      failed = 0                                                                â”‚
â”‚                                                                                â”‚
â”‚      with ThreadPoolExecutor(max_workers=self.stage1_workers) as executor:    â”‚
â”‚          future_to_date = {                                                    â”‚
â”‚              executor.submit(self._fetch_grouped_day, date): date             â”‚
â”‚              for date in trading_dates                                         â”‚
â”‚          }                                                                      â”‚
â”‚                                                                                â”‚
â”‚          for future in as_completed(future_to_date):                          â”‚
â”‚              date_str = future_to_date[future]                                â”‚
â”‚              completed += 1                                                     â”‚
â”‚                                                                                â”‚
â”‚              try:                                                              â”‚
â”‚                  data = future.result()                                        â”‚
â”‚                  if data is not None and not data.empty:                       â”‚
â”‚                      all_data.append(data)                                     â”‚
â”‚                  else:                                                         â”‚
â”‚                      failed += 1                                               â”‚
â”‚                                                                                â”‚
â”‚                  if completed % 100 == 0:                                      â”‚
â”‚                      print(f"âš¡ Progress: {completed}/{len(trading_dates)}")  â”‚
â”‚                                                                                â”‚
â”‚              except Exception as e:                                            â”‚
â”‚                  failed += 1                                                    â”‚
â”‚                  print(f"âš ï¸  Error fetching {date_str}: {e}")                 â”‚
â”‚                                                                                â”‚
â”‚      if all_data:                                                              â”‚
â”‚          return pd.concat(all_data)                                            â”‚
â”‚      return pd.DataFrame()                                                     â”‚
â”‚                                                                                â”‚
â”‚  def _fetch_grouped_day(self, date_str: str) -> Optional[pd.DataFrame]:       â”‚
â”‚      """Fetch all tickers for ONE trading day"""                              â”‚
â”‚      url = f"{self.base_url}/v2/aggs/grouped/locale/us/market/stocks/{date_str}"â”‚
â”‚      params = {                                                                â”‚
â”‚          'adjusted': 'false',                                                  â”‚
â”‚          'apiKey': self.api_key                                                â”‚
â”‚      }                                                                         â”‚
â”‚                                                                                â”‚
â”‚      try:                                                                      â”‚
â”‚          response = self.session.get(url, params=params, timeout=30)          â”‚
â”‚          response.raise_for_status()                                            â”‚
â”‚                                                                                â”‚
â”‚          data = response.json()                                                â”‚
â”‚          if 'results' not in data or not data['results']:                     â”‚
â”‚              return None                                                       â”‚
â”‚                                                                                â”‚
â”‚          results = data['results']                                             â”‚
â”‚          df = pd.DataFrame(results)                                            â”‚
â”‚          return df                                                             â”‚
â”‚                                                                                â”‚
â”‚      except Exception as e:                                                    â”‚
â”‚          print(f"âš ï¸  Error for {date_str}: {e}")                             â”‚
â”‚          return None                                                           â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                                â”‚
â”‚          print(f"ğŸš€ Standardized Scanner Initialized")                         â”‚
â”‚          print(f"ğŸ“… Signal Range: {self.d0_start} to {self.d0_end}")            â”‚
â”‚          print(f"ğŸ“Š Historical Range: {self.scan_start} to {self.scan_end}")    â”‚
â”‚                                                                                â”‚
â”‚      # ======================================================================== â”‚
â”‚      #  STAGE 1: MARKET UNIVERSE OPTIMIZATION                                   â”‚
â”‚      # ======================================================================== â”‚
â”‚                                                                                â”‚
â”‚      def execute_stage1_market_universe_optimization(self) -> list:          â”‚
â”‚          """                                                                   â”‚
â”‚          Stage 1: Fetch and filter ALL market tickers                        â”‚
â”‚                                                                                â”‚
â”‚          Returns:                                                               â”‚
â”‚              List of qualified ticker symbols (strings)                       â”‚
â”‚          """                                                                   â”‚
â”‚          import requests                                                      â”‚
â”‚          from datetime import datetime                                          â”‚
â”‚          from concurrent.futures import ThreadPoolExecutor, as_completed     â”‚
â”‚          import time                                                            â”‚
â”‚                                                                                â”‚
â”‚          print(f"\\n{'='*70}")                                                â”‚
â”‚          print("ğŸš€ STAGE 1: MARKET UNIVERSE OPTIMIZATION")                       â”‚
â”‚          print(f"{'='*70}")                                                â”‚
â”‚                                                                                â”‚
â”‚          # Step 1: Fetch ALL tickers from Polygon                             â”‚
â”‚          all_tickers = self._fetch_all_market_tickers()                       â”‚
â”‚          print(f"ğŸ“¡ Fetched {len(all_tickers)} total tickers from market")    â”‚
â”‚                                                                                â”‚
â”‚          # Step 2: Apply smart filters to reduce dataset                      â”‚
â”‚          qualified_tickers = self._apply_smart_filters(all_tickers)          â”‚
â”‚          print(f"âœ… Qualified universe: {len(qualified_tickers)} symbols "        â”‚
â”‚                f"({len(qualified_tickers)/len(all_tickers)*100}% of market)") â”‚
â”‚                                                                                â”‚
â”‚          return qualified_tickers                                               â”‚
â”‚                                                                                â”‚
â”‚      def _fetch_all_market_tickers(self) -> list:                             â”‚
â”‚          """Fetch ALL tickers from Polygon snapshot endpoint"""               â”‚
â”‚          try:                                                                â”‚
â”‚              # Polygon snapshot endpoint - ALL tickers in ONE call          â”‚
â”‚              url = f"{self.base_url}/v3/snapshot/locale/us/markets/stocks/tickers" â”‚
â”‚              params = {                                                        â”‚
â”‚                  'apiKey': self.api_key                                       â”‚
â”‚              }                                                                  â”‚
â”‚                                                                                â”‚
â”‚              response = self.session.get(url, params=params, timeout=30)     â”‚
â”‚              response.raise_for_status()                                      â”‚
â”‚                                                                                â”‚
â”‚              data = response.json()                                            â”‚
â”‚              return data.get('results', [])                                  â”‚
â”‚                                                                                â”‚
â”‚          except Exception as e:                                               â”‚
â”‚              print(f"âŒ Error fetching market tickers: {e}")                   â”‚
â”‚              # Fallback to predefined list if API fails                        â”‚
â”‚              return self._get_fallback_ticker_universe()                      â”‚
â”‚                                                                                â”‚
â”‚      def _apply_smart_filters(self, tickers: list) -> list:                  â”‚
â”‚          """Apply intelligent pre-filters to reduce dataset by ~99%"""       â”‚
â”‚          qualified = []                                                       â”‚
â”‚                                                                                â”‚
â”‚          for ticker in tickers:                                              â”‚
â”‚              try:                                                            â”‚
â”‚                  # Get latest price data for filtering                       â”‚
â”‚                  url = f"{self.base_url}/v2/aggs/ticker/{ticker}/prev"     â”‚
â”‚                  params = {'apiKey': self.api_key}                            â”‚
â”‚                  response = self.session.get(url, params=params, timeout=10) â”‚
â”‚                                                                                  â”‚
â”‚                  if response.status_code != 200:                             â”‚
â”‚                      continue                                                 â”‚
â”‚                                                                                  â”‚
â”‚                  data = response.json()                                       â”‚
â”‚                  if not data or 'results' not in data or len(data['results']) == 0: â”‚
â”‚                      continue                                                 â”‚
â”‚                                                                                  â”‚
â”‚                  prev_candle = data['results'][0]                             â”‚
â”‚                  prev_close = prev_candle.get('c', 0)                         â”‚
â”‚                  volume = prev_candle.get('v', 0)                             â”‚
â”‚                                                                                  â”‚
â”‚                  # Apply standard filters                                      â”‚
â”‚                  if prev_close >= 8.0:  # Price minimum                      â”‚
â”‚                      qualified.append(ticker)                                â”‚
â”‚                                                                                  â”‚
â”‚              except Exception:                                               â”‚
â”‚                  continue  # Skip problematic tickers                       â”‚
â”‚                                                                                  â”‚
â”‚          return qualified                                                      â”‚
â”‚                                                                                â”‚
â”‚      # ======================================================================== â”‚
â”‚      #  STAGE 2: DATA ENRICHMENT                                                â”‚
â”‚      # ======================================================================== â”‚
â”‚                                                                                â”‚
â”‚      def execute_stage2_data_enrichment(self, qualified_tickers: list) -> dict: â”‚
â”‚          """                                                                   â”‚
â”‚          Stage 2: Fetch and enrich data for qualified symbols                 â”‚
â”‚                                                                                â”‚
â”‚          Args:                                                                 â”‚
â”‚              qualified_tickers: List of ticker symbols to process           â”‚
â”‚                                                                                â”‚
â”‚          Returns:                                                               â”‚
â”‚              Dictionary mapping ticker â†’ enriched DataFrame                   â”‚
â”‚          """                                                                   â”‚
â”‚          import pandas as pd                                                   â”‚
â”‚          from concurrent.futures import ThreadPoolExecutor, as_completed     â”‚
â”‚          import time                                                            â”‚
â”‚                                                                                â”‚
â”‚          print(f"\\n{'='*70}")                                                â”‚
â”‚          print("ğŸš€ STAGE 2: DATA ENRICHMENT")                                  â”‚
â”‚          print(f"{'='*70}")                                                â”‚
â”‚          print(f"ğŸ“Š Enriching {len(qualified_tickers)} qualified symbols...")   â”‚
â”‚                                                                                â”‚
â”‚          enriched_data = {}                                                     â”‚
â”‚          completed = 0                                                         â”‚
â”‚                                                                                â”‚
â”‚          with ThreadPoolExecutor(max_workers=self.stage2_workers) as executor: â”‚
â”‚              future_to_ticker = {                                               â”‚
â”‚                  executor.submit(self._fetch_and_enrich_ticker, ticker): ticker â”‚
â”‚                  for ticker in qualified_tickers                               â”‚
â”‚              }                                                                   â”‚
â”‚                                                                                â”‚
â”‚              for future in as_completed(future_to_ticker):                   â”‚
â”‚                  ticker = future_to_ticker[future]                              â”‚
â”‚                  completed += 1                                               â”‚
â”‚                                                                                â”‚
â”‚                  try:                                                        â”‚
â”‚                      df = future.result()                                    â”‚
â”‚                      if df is not None and not df.empty:                     â”‚
â”‚                          enriched_data[ticker] = df                           â”‚
â”‚                  except Exception as e:                                       â”‚
â”‚                      print(f"âš ï¸  Failed to enrich {ticker}: {e}")             â”‚
â”‚                                                                                â”‚
â”‚                  if completed % 50 == 0:                                    â”‚
â”‚                      print(f"âš¡ Progress: {completed}/{len(qualified_tickers)}") â”‚
â”‚                                                                                â”‚
â”‚          print(f"âœ… Enriched {len(enriched_data)} symbols successfully")      â”‚
â”‚          return enriched_data                                                   â”‚
â”‚                                                                                â”‚
â”‚      def _fetch_and_enrich_ticker(self, ticker: str):                          â”‚
â”‚          """Fetch and enrich data for a single ticker"""                        â”‚
â”‚          import pandas as pd                                                   â”‚
â”‚          import time                                                            â”‚
â”‚                                                                                â”‚
â”‚          try:                                                                â”‚
â”‚              # Fetch daily bars                                                â”‚
â”‚              url = f"{self.base_url}/v2/aggs/ticker/{ticker}/range"           â”‚
â”‚              params = {                                                        â”‚
â”‚                  'apiKey': self.api_key,                                       â”‚
â”‚                  'adjusted': 'false',                                          â”‚
â”‚                  'sort': 'asc',                                                â”‚
â”‚                  'limit': 5000                                                 â”‚
â”‚              }                                                                  â”‚
â”‚                                                                                â”‚
â”‚              response = self.session.get(url, params=params, timeout=30)     â”‚
â”‚              response.raise_for_status()                                      â”‚
â”‚                                                                                â”‚
â”‚              data = response.json()                                            â”‚
â”‚              if not data or 'results' not in data:                            â”‚
â”‚                  return None                                                   â”‚
â”‚                                                                                â”‚
â”‚              df = pd.DataFrame(data['results'])                               â”‚
â”‚              if df.empty:                                                      â”‚
â”‚                  return None                                                   â”‚
â”‚                                                                                â”‚
â”‚              # Parse dates                                                   â”‚
â”‚              df['timestamp'] = pd.to_datetime(df['t'])                         â”‚
â”‚              df.set_index('timestamp', inplace=True)                          â”‚
â”‚                                                                                â”‚
â”‚              # Compute technical indicators                                   â”‚
â”‚              df = self._compute_indicators(df)                               â”‚
â”‚                                                                                â”‚
â”‚              return df                                                        â”‚
â”‚                                                                                â”‚
â”‚          except Exception as e:                                               â”‚
â”‚              print(f"Error fetching {ticker}: {e}")                           â”‚
â”‚              return None                                                       â”‚
â”‚                                                                                â”‚
â”‚      def _compute_indicators(self, df: pd.DataFrame) -> pd.DataFrame:         â”‚
â”‚          """Compute all required technical indicators"""                      â”‚
â”‚          import pandas as pd                                                   â”‚
â”‚          import numpy as np                                                    â”‚
â”‚                                                                                â”‚
â”‚          # Moving averages                                                   â”‚
â”‚          df['ema9'] = df['c'].ewm(span=9, adjust=False).mean()               â”‚
â”‚          df['ema20'] = df['c'].ewm(span=20, adjust=False).mean()             â”‚
â”‚          df['sma50'] = df['c'].rolling(window=50).mean()                     â”‚
â”‚                                                                                â”‚
â”‚          # ATR (Average True Range)                                          â”‚
â”‚          df['high_low'] = df['h'] - df['l']                                   â”‚
â”‚          df['atr'] = df['high_low'].rolling(window=14).mean()                 â”‚
â”‚                                                                                â”‚
â”‚          # Volume metrics                                                   â”‚
â”‚          df['adv20'] = df['v'].rolling(window=20).mean()                     â”‚
â”‚                                                                                â”‚
â”‚          # Price changes                                                    â”‚
â”‚          df['pct_change'] = df['c'].pct_change()                              â”‚
â”‚                                                                                â”‚
â”‚          return df                                                            â”‚
â”‚                                                                                â”‚
â”‚      # ======================================================================== â”‚
â”‚      #  STAGE 3: PATTERN DETECTION                                              â”‚
â”‚      # ======================================================================== â”‚
â”‚                                                                                â”‚
â”‚      def execute_stage3_pattern_detection(self, enriched_data: dict) -> list: â”‚
â”‚          """                                                                   â”‚
â”‚          Stage 3: Execute user's pattern logic on enriched data              â”‚
â”‚                                                                                â”‚
â”‚          Args:                                                                 â”‚
â”‚              enriched_data: Dictionary of ticker â†’ DataFrame               â”‚
â”‚                                                                                â”‚
â”‚          Returns:                                                               â”‚
â”‚              List of signal dictionaries with full details                    â”‚
â”‚          """                                                                   â”‚
â”‚          import pandas as pd                                                   â”‚
â”‚          from concurrent.futures import ThreadPoolExecutor, as_completed     â”‚
â”‚                                                                                â”‚
â”‚          print(f"\\n{'='*70}")                                                â”‚
â”‚          print("ğŸš€ STAGE 3: PATTERN DETECTION")                               â”‚
â”‚          print(f"{'='*70}")                                                â”‚
â”‚          print(f"ğŸ” Scanning {len(enriched_data)} enriched symbols...")        â”‚
â”‚                                                                                â”‚
â”‚          all_signals = []                                                      â”‚
â”‚          completed = 0                                                         â”‚
â”‚                                                                                â”‚
â”‚          with ThreadPoolExecutor(max_workers=self.stage3_workers) as executor: â”‚
â”‚              future_to_ticker = {                                               â”‚
â”‚                  executor.submit(self._scan_symbol_pattern, ticker, df):     â”‚
â”‚                  for ticker, df in enriched_data.items()                     â”‚
â”‚              }                                                                   â”‚
â”‚                                                                                â”‚
â”‚              for future in as_completed(future_to_ticker):                   â”‚
â”‚                  completed += 1                                               â”‚
â”‚                                                                                  â”‚
â”‚                  try:                                                        â”‚
â”‚                      signals = future.result()                                 â”‚
â”‚                      if signals:                                              â”‚
â”‚                          all_signals.extend(signals)                         â”‚
â”‚                  except Exception as e:                                       â”‚
â”‚                      pass  # Continue scanning other symbols                â”‚
â”‚                                                                                  â”‚
â”‚                  if completed % 20 == 0:                                    â”‚
â”‚                      print(f"âš¡ Progress: {completed}/{len(enriched_data)} " â”‚
â”‚                            f"signals found: {len(all_signals)}")           â”‚
â”‚                                                                                â”‚
â”‚          print(f"âœ… Pattern detection complete: {len(all_signals)} signals")  â”‚
â”‚          return all_signals                                                    â”‚
â”‚                                                                                â”‚
â”‚      def _scan_symbol_pattern(self, ticker: str, df: pd.DataFrame) -> list:   â”‚
â”‚          """                                                                   â”‚
â”‚          Execute user's original pattern logic on enriched data              â”‚
â”‚                                                                                â”‚
â”‚          This is where the user's strategy gets applied to the market       â”‚
â”‚          """                                                                   â”‚
â”‚          import pandas as pd                                                   â”‚
â”‚          import numpy as np                                                    â”‚
â”‚          from datetime import datetime                                          â”‚
â”‚                                                                                â”‚
â”‚          signals = []                                                         â”‚
â”‚                                                                                â”‚
â”‚          # Filter to user's date range (D0)                                 â”‚
â”‚          d0_start = pd.to_datetime(self.d0_start)                             â”‚
â”‚          d0_end = pd.to_datetime(self.d0_end)                                 â”‚
â”‚          df = df[(df.index >= d0_start) & (df.index <= d0_end)]                â”‚
â”‚                                                                                â”‚
â”‚          # ==================================================================== â”‚
â”‚          #  USER'S PATTERN LOGIC GOES HERE                                 â”‚
â”‚          # ==================================================================== â”‚
â”‚          # Transform their original logic to work with enriched data        â”‚
â”‚          # Use self.params dictionary for all parameter values             â”‚
â”‚          # ==================================================================== â”‚
â”‚                                                                                â”‚
â”‚          for idx, row in df.iterrows():                                      â”‚
â”‚              try:                                                            â”‚
â”‚                  # Check user's pattern conditions                          â”‚
â”‚                  if self._check_pattern_conditions(row):                     â”‚
â”‚                      signals.append({                                        â”‚
â”‚                          'symbol': ticker,                                 â”‚
â”‚                          'date': idx.strftime('%Y-%m-%d'),               â”‚
â”‚                          'price': row['c'],                                 â”‚
â”‚                          'volume': row['v'],                               â”‚
â”‚                          # Add all relevant details                             â”‚
â”‚                          'params': self.params.copy()                       â”‚
â”‚                      })                                                       â”‚
â”‚              except Exception as e:                                           â”‚
â”‚                  continue  # Skip problematic rows                         â”‚
â”‚                                                                                â”‚
â”‚          return signals                                                         â”‚
â”‚                                                                                â”‚
â”‚      def _check_pattern_conditions(self, row) -> bool:                       â”‚
â”‚          """                                                                   â”‚
â”‚          Check if row matches user's pattern conditions                     â”‚
â”‚          Override this method with user's specific logic                     â”‚
â”‚          """                                                                   â”‚
â”‚          # Default implementation - override in subclass                     â”‚
â”‚          return True                                                            â”‚
â”‚                                                                                â”‚
â”‚      # ======================================================================== â”‚
â”‚      #  MAIN EXECUTION METHOD                                                  â”‚
â”‚      # ======================================================================== â”‚
â”‚                                                                                â”‚
â”‚      def run_formatted_scan(self) -> list:                                    â”‚
â”‚          """                                                                   â”‚
â”‚          Main execution method - runs all 3 stages and returns results       â”‚
â”‚                                                                                â”‚
â”‚          Returns:                                                               â”‚
â”‚              List of signal dictionaries                                      â”‚
â”‚          """                                                                   â”‚
â”‚          import time                                                            â”‚
â”‚                                                                                â”‚
â”‚          start_time = time.time()                                             â”‚
â”‚                                                                                â”‚
â”‚          # Stage 1: Get qualified universe                                   â”‚
â”‚          qualified_tickers = self.execute_stage1_market_universe_optimization() â”‚
â”‚                                                                                â”‚
â”‚          if not qualified_tickers:                                            â”‚
â”‚              print("âŒ No qualified tickers found")                           â”‚
â”‚              return []                                                        â”‚
â”‚                                                                                â”‚
â”‚          # Stage 2: Enrich data                                               â”‚
â”‚          enriched_data = self.execute_stage2_data_enrichment(qualified_tickers) â”‚
â”‚                                                                                â”‚
â”‚          if not enriched_data:                                                â”‚
â”‚              print("âŒ No enriched data available")                          â”‚
â”‚              return []                                                        â”‚
â”‚                                                                                â”‚
â”‚          # Stage 3: Pattern detection                                        â”‚
â”‚          signals = self.execute_stage3_pattern_detection(enriched_data)      â”‚
â”‚                                                                                â”‚
â”‚          elapsed = time.time() - start_time                                   â”‚
â”‚          print(f"\\nğŸ‰ Scan complete in {elapsed}s: {len(signals)} signals") â”‚
â”‚                                                                                â”‚
â”‚          return signals                                                        â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. REQUIRED IMPORTS BLOCK                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  # MUST appear at the top of EVERY scanner file:                            â”‚
â”‚                                                                                â”‚
â”‚  import pandas as pd                                                           â”‚
â”‚  import numpy as np                                                            â”‚
â”‚  import requests                                                               â”‚
â”‚  import time                                                                   â”‚
â”‚  from datetime import datetime, timedelta                                   â”‚
â”‚  from concurrent.futures import ThreadPoolExecutor, as_completed             â”‚
â”‚  import multiprocessing as mp                                                 â”‚
â”‚  from typing import List, Dict, Optional, Tuple, Any                         â”‚
â”‚  from requests.adapters import HTTPAdapter                                   â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PARAMETER BLOCK STRUCTURE                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  # Extract user's parameters and preserve EXACTLY:                           â”‚
â”‚                                                                                â”‚
â”‚  self.params = {                                                              â”‚
â”‚      # ALL numeric parameters preserve decimal precision:                     â”‚
â”‚      "price_min": 8.0,                                                       â”‚
â”‚      "adv_min_usd": 30_000_000,                                             â”‚
â”‚      "lookback_days": 1000,                                                 â”‚
â”‚                                                                                â”‚
â”‚      # Boolean parameters use True/False (not strings):                       â”‚
â”‚      "require_volume_confirm": True,                                         â”‚
â”‚      "enforce_filters": False,                                              â”‚
â”‚                                                                                â”‚
â”‚      # String parameters use quotes:                                        â”‚
â”‚      "trigger_mode": "D1_or_D2",                                            â”‚
â”‚  }                                                                           â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ERROR HANDLING PATTERN                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  # Wrap all API calls in try-except:                                        â”‚
â”‚                                                                                â”‚
â”‚  try:                                                                       â”‚
â”‚      response = self.session.get(url, params=params, timeout=30)          â”‚
â”‚      response.raise_for_status()                                            â”‚
â”‚  except requests.exceptions.RequestException as e:                         â”‚
â”‚      print(f"âš ï¸  API Error for {ticker}: {e}")                            â”‚
â”‚      return None  # or continue to next symbol                             â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. PERFORMANCE BEST PRACTICES                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  âœ… DO:                                                                      â”‚
â”‚  - Use ThreadPoolExecutor for parallel processing                         â”‚
â”‚  - Set timeout on all requests (10-30 seconds)                            â”‚
â”‚  - Process in batches (100-200 symbols per batch)                         â”‚
â”‚  - Print progress updates every 50-100 symbols                            â”‚
â”‚  - Continue on individual symbol failures (fail gracefully)              â”‚
â”‚                                                                                â”‚
â”‚  âŒ DON'T:                                                                  â”‚
â”‚  - Process symbols sequentially (too slow)                                â”‚
â”‚  - Wait indefinitely for API responses (add timeouts)                     â”‚
â”‚  - Fail entire scan if one symbol errors                                  â”‚
â”‚  - Print progress for every symbol (too much output)                      â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. OUTPUT FORMAT                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                â”‚
â”‚  # Return signals in standard format:                                       â”‚
â”‚                                                                                â”‚
â”‚  signals = [                                                                 â”‚
â”‚      {                                                                         â”‚
â”‚          'symbol': 'AAPL',                                                   â”‚
â”‚          'date': '2025-01-15',                                             â”‚
â”‚          'price': 175.23,                                                   â”‚
â”‚          'volume': 45_000_000,                                             â”‚
â”‚          'indicator1': 0.95,    # EMA9 value                             â”‚
â”‚          'indicator2': 'triggered',  # Pattern status                      â”‚
â”‚          # Add all relevant computed values                                 â”‚
â”‚      }                                                                         â”‚
â”‚  ]                                                                          â”‚
â”‚                                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TRANSFORMATION CHECKLIST                                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                â•‘
â•‘  When transforming user code, ENSURE:                                        â•‘
â•‘                                                                                â•‘
â•‘  â˜‘  Extract ALL parameters from user's code (preserving exact values)       â•‘
â•‘  â˜‘  Transform hardcoded SYMBOLS list into market universe fetch            â•‘
â•‘  â˜‘  Wrap sequential logic in parallel execution pattern                    â•‘
â•‘  â˜‘  Add proper error handling with continue statements                       â•‘
â•‘  â˜‘  Add progress indicators for user experience                           â•‘
â•‘  â˜‘  Use HTTP session pooling for API efficiency                            â•‘
â•‘  â˜‘  Filter results to user's requested date range (D0)                      â•‘
â•‘  â˜‘  Return results in standard dictionary format                            â•‘
â•‘                                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`;

// ===== PROMPT GENERATION SERVICE =====

export class PromptGenerator {
  /**
   * Generate formatting prompt with code context
   *
   * Uses quick MASTER_FORMATTING_PROMPT for known scanner types
   * For unknown types or when detailed guidance needed, use generateDetailedPrompt()
   */
  static generateFormattingPrompt(code: string, filename: string): string {
    let prompt = '';

    // Add the master prompt
    prompt += MASTER_FORMATTING_PROMPT;

    // Add filename context
    prompt += `\n\n## FILE CONTEXT\n`;
    prompt += `Filename: ${filename}\n`;
    prompt += `Code Length: ${code.length} characters\n`;
    prompt += `Lines: ${code.split('\n').length}\n`;

    // Extract parameters from code
    const params = this.extractParameters(code);
    if (params.length > 0) {
      prompt += `\n## DETECTED PARAMETERS (${params.length})\n`;
      params.forEach(p => {
        prompt += `- ${p.name}: ${p.value}\n`;
      });
      prompt += `\nEnsure ALL ${params.length} parameters are preserved with EXACT values.\n`;
    }

    // CRITICAL: Include the actual code to format!
    prompt += `\n## ORIGINAL CODE TO TRANSFORM\n`;
    prompt += code;

    return prompt;
  }

  /**
   * Generate detailed formatting prompt with full standardization reference
   *
   * Use this for:
   * - Unknown/custom scanner types
   * - Complex code that doesn't match templates
   * - When AI needs more explicit structure guidance
   */
  static generateDetailedPrompt(code: string, filename: string, scannerType: string = 'Unknown'): string {
    let prompt = '';

    // Add the comprehensive standardization reference
    prompt += MASTER_STANDARDIZATION_REFERENCE;

    // Add filename context
    prompt += `\n\n## FILE CONTEXT\n`;
    prompt += `Filename: ${filename}\n`;
    prompt += `Code Length: ${code.length} characters\n`;
    prompt += `Lines: ${code.split('\n').length}\n`;
    prompt += `Scanner Type: ${scannerType}\n`;

    // Extract parameters from code
    const params = this.extractParameters(code);
    if (params.length > 0) {
      prompt += `\n## DETECTED PARAMETERS (${params.length})\n`;
      params.forEach(p => {
        prompt += `- ${p.name}: ${p.value}\n`;
      });
      prompt += `\nâœ… MANDATORY: ALL ${params.length} parameters MUST be preserved with EXACT values.\n`;
      prompt += `Add them to self.params dictionary in __init__ method.\n`;
    }

    // Extract symbol list if present
    const symbolsMatch = code.match(/SYMBOLS\s*=\s*\[([^\]]+)\]/);
    if (symbolsMatch) {
      const symbolsList = symbolsMatch[1].split(',').map(s => s.trim().replace(/['"]/g, '')).slice(0, 5);
      prompt += `\n## DETECTED SYMBOLS\n`;
      prompt += `Original code has ${symbolsMatch[1].split(',').length} hardcoded symbols.\n`;
      prompt += `âš ï¸  CRITICAL: Replace hardcoded SYMBOLS with market universe fetch.\n`;
      prompt += `Use execute_stage1_market_universe_optimization() method from template.\n`;
    }

    // CRITICAL: Include the actual code to format!
    prompt += `\n## ORIGINAL CODE TO TRANSFORM\n`;
    prompt += code;

    // Add transformation instructions
    prompt += `\n\n## CRITICAL TRANSFORMATION INSTRUCTIONS\n`;
    prompt += `1. Follow the STANDARDIZED_SCANNER structure above EXACTLY\n`;
    prompt += `2. Extract user's pattern logic and place in _scan_symbol_pattern() method\n`;
    prompt += `3. Preserve ALL parameters with EXACT values in self.params dictionary\n`;
    prompt += `4. Replace hardcoded SYMBOLS list with market universe fetch (Stage 1)\n`;
    prompt += `5. Add proper error handling with try-except blocks\n`;
    prompt += `6. Add progress indicators (print statements every 50-100 symbols)\n`;
    prompt += `7. Return results in standard signal dictionary format\n`;
    prompt += `8. Add type hints to all method signatures\n`;
    prompt += `9. Include docstrings for all methods\n`;
    prompt += `10. Test that output matches: List[Dict] with symbol, date, price keys\n`;

    // ğŸ¯ CRITICAL: Add column naming requirements to prevent pandas errors
    prompt += `\n\n## ğŸš¨ CRITICAL: COLUMN NAMING AND PANDAS SYNTAX RULES\n`;
    prompt += `STAGE 1 DATA FETCHING (fetch_all_grouped_data method):\n`;
    prompt += `\`\`\`\n`;
    prompt += `# âœ… CORRECT: Rename Polygon API columns IMMEDIATELY after fetching\n`;
    prompt += `df = pd.DataFrame(data['results'])\n`;
    prompt += `df['date'] = pd.to_datetime(date_str)\n`;
    prompt += `df = df.rename(columns={\n`;
    prompt += `    'T': 'ticker',\n`;
    prompt += `    'o': 'open',\n`;
    prompt += `    'h': 'high',\n`;
    prompt += `    'l': 'low',\n`;
    prompt += `    'c': 'close',\n`;
    prompt += `    'v': 'volume',\n`;
    prompt += `    'vw': 'vwap',\n`;
    prompt += `    't': 'timestamp'\n`;
    prompt += `})\n`;
    prompt += `return df[['ticker', 'date', 'open', 'high', 'low', 'close', 'volume']]\n`;
    prompt += `\`\`\`\n`;
    prompt += `\n`;
    prompt += `STAGE 2 FEATURE COMPUTATION (compute_simple_features method):\n`;
    prompt += `\`\`\`\n`;
    prompt += `# âœ… CORRECT: Use renamed columns with .transform() method\n`;
    prompt += `df = df.sort_values(['ticker', 'date'])\n`;
    prompt += `df['ADV20'] = (df['close'] * df['volume']).groupby(df['ticker']).transform(\n`;
    prompt += `    lambda x: x.rolling(window=20, min_periods=20).mean()\n`;
    prompt += `)\n`;
    prompt += `\`\`\`\n`;
    prompt += `\n`;
    prompt += `# âŒ WRONG: Do NOT use Polygon column names ('T', 'c', 'v')\n`;
    prompt += `# âŒ WRONG: Do NOT use .reset_index() which causes duplicate labels error\n`;
    prompt += `# âŒ WRONG: Do NOT use .mean() directly without .transform()\n`;
    prompt += `# âŒ WRONG: Do NOT use .groupby().transform(lambda x: x.max(axis=1)) - causes KeyError!\n`;
    prompt += `# âŒ WRONG: Do NOT use axis parameter in transform lambda for Series operations\n`;
    prompt += `\n`;
    prompt += `MANDATORY: All column names must be renamed (ticker, close, volume, etc.) BEFORE any computations!\n`;
    prompt += `This prevents: "ValueError: cannot reindex on an axis with duplicate labels"\n`;
    prompt += `\n`;
    prompt += `For computing True Range (max of multiple columns):\n`;
    prompt += `  âœ… CORRECT: df['TR'] = df[['high_low', 'high_prev_close', 'low_prev_close']].max(axis=1)\n`;
    prompt += `  âŒ WRONG: df['TR'] = df.groupby('ticker')[[...]].transform(lambda x: x.max(axis=1))\n`;

    // Add execute method template with proper stage reporting
    prompt += `\n\n## ğŸ“Š EXECUTE METHOD TEMPLATE (Follow This Exact Structure)\n`;
    prompt += `\`\`\`python\n`;
    prompt += `def execute(self) -> pd.DataFrame:\n`;
    prompt += `    """\n`;
    prompt += `    Main execution pipeline - orchestrates all 3 stages\n`;
    prompt += `    """\n`;
    prompt += `    print(f"\\n{'=' \* 70}")\n`;
    prompt += `    print("ğŸš€ {SCANNER_NAME} SCANNER - GROUPED ENDPOINT ARCHITECTURE")\n`;
    prompt += `    print(f"{'=' \* 70}")\n`;
    prompt += `    print(f"ğŸ“… Signal Range: {self.d0_start} to {self.d0_end}")\n`;
    prompt += `    print(f"ğŸ“Š Historical Range: {self.scan_start} to {self.scan_end}")\n`;
    prompt += `\n`;
    prompt += `    # Get trading dates\n`;
    prompt += `    trading_dates = self.get_trading_dates(self.scan_start, self.scan_end)\n`;
    prompt += `    print(f"ğŸ“… Trading days: {len(trading_dates)}")\n`;
    prompt += `\n`;
    prompt += `    # Stage 1: Fetch grouped data\n`;
    prompt += `    print(f"\\n{'=' \* 70}")\n`;
    prompt += `    print("ğŸš€ STAGE 1: FETCH GROUPED DATA")\n`;
    prompt += `    print(f"{'=' \* 70}")\n`;
    prompt += `    df = self.fetch_all_grouped_data(trading_dates)\n`;
    prompt += `\n`;
    prompt += `    if df.empty:\n`;
    prompt += `        print("âŒ No data available!")\n`;
    prompt += `        return pd.DataFrame()\n`;
    prompt += `\n`;
    prompt += `    print(f"âœ… Fetched {len(df)} data points")\n`;
    prompt += `\n`;
    prompt += `    # Stage 2: Compute simple features + apply smart filters\n`;
    prompt += `    print(f"\\n{'=' \* 70}")\n`;
    prompt += `    print("ğŸš€ STAGE 2: COMPUTE FEATURES + APPLY FILTERS")\n`;
    prompt += `    print(f"{'=' \* 70}")\n`;
    prompt += `    df = self.compute_simple_features(df)\n`;
    prompt += `    df = self.apply_smart_filters(df)\n`;
    prompt += `\n`;
    prompt += `    if df.empty:\n`;
    prompt += `        print("âŒ No rows passed smart filters!")\n`;
    prompt += `        return pd.DataFrame()\n`;
    prompt += `\n`;
    prompt += `    print(f"âœ… Filtered to {len(df)} qualified rows")\n`;
    prompt += `\n`;
    prompt += `    # Stage 3: Compute full features + detect patterns\n`;
    prompt += `    print(f"\\n{'=' \* 70}")\n`;
    prompt += `    print("ğŸš€ STAGE 3: COMPUTE FULL FEATURES + SCAN PATTERNS")\n`;
    prompt += `    print(f"{'=' \* 70}")\n`;
    prompt += `    df = self.compute_full_features(df)\n`;
    prompt += `    signals = self.detect_patterns(df)\n`;
    prompt += `\n`;
    prompt += `    if signals.empty:\n`;
    prompt += `        print("âŒ No signals found!")\n`;
    prompt += `        return pd.DataFrame()\n`;
    prompt += `\n`;
    prompt += `    # Filter to D0 range\n`;
    prompt += `    signals = signals[\n`;
    prompt += `        (signals['Date'] >= self.d0_start) &\n`;
    prompt += `        (signals['Date'] <= self.d0_end)\n`;
    prompt += `    ]\n`;
    prompt += `\n`;
    prompt += `    # Sort by date (chronological order)\n`;
    prompt += `    signals = signals.sort_values('Date').reset_index(drop=True)\n`;
    prompt += `\n`;
    prompt += `    print(f"\\n{'=' \* 70}")\n`;
    prompt += `    print(f"âœ… SCAN COMPLETE")\n`;
    prompt += `    print(f"{'=' \* 70}")\n`;
    prompt += `    print(f"ğŸ“Š Final signals (D0 range): {len(signals):,}")\n`;
    prompt += `    print(f"ğŸ“Š Unique tickers: {signals['Ticker'].nunique():,}")\n`;
    prompt += `\n`;
    prompt += `    # Print all results\n`;
    prompt += `    if len(signals) > 0:\n`;
    prompt += `        print(f"\\n{'=' \* 70}")\n`;
    prompt += `        print("ğŸ“Š SIGNALS FOUND:")\n`;
    prompt += `        print(f"{'=' \* 70}")\n`;
    prompt += `        for idx, row in signals.iterrows():\n`;
    prompt += `            print(f"  {row['Ticker']} | {row['Date']} | Close: $\{row['Close']} | Volume: {row['Volume']}")\n`;
    prompt += `\n`;
    prompt += `    return signals\n`;
    prompt += `\`\`\`\n`;

    // Add explicit True Range computation example to prevent the axis error
    prompt += `\n\n## ğŸ¯ TRUE RANGE COMPUTATION EXAMPLE (Stage 3)\n`;
    prompt += `\`\`\`python\n`;
    prompt += `def compute_full_features(self, df: pd.DataFrame) -> pd.DataFrame:\n`;
    prompt += `    """\n`;
    prompt += `    Compute all features for pattern detection\n`;
    prompt += `    """\n`;
    prompt += `    print(f"ğŸ“ˆ Computing full features for {len(df):,} rows...")\n`;
    prompt += `\n`;
    prompt += `    # Compute True Range and ATR\n`;
    prompt += `    df['high_low'] = df['high'] - df['low']\n`;
    prompt += `    df['high_prev_close'] = (df['high'] - df['close'].shift(1)).abs()\n`;
    prompt += `    df['low_prev_close'] = (df['low'] - df['close'].shift(1)).abs()\n`;
    prompt += `\n`;
    prompt += `    # âœ… CORRECT: Direct max computation across columns\n`;
    prompt += `    df['TR'] = df[['high_low', 'high_prev_close', 'low_prev_close']].max(axis=1)\n`;
    prompt += `\n`;
    prompt += `    # Then compute ATR using groupby().transform()\n`;
    prompt += `    df['ATR_raw'] = df.groupby('ticker')['TR'].transform(\n`;
    prompt += `        lambda x: x.rolling(14, min_periods=14).mean()\n`;
    prompt += `    )\n`;
    prompt += `    df['ATR'] = df.groupby('ticker')['ATR_raw'].shift(1)\n`;
    prompt += `\n`;
    prompt += `    # ... rest of features\n`;
    prompt += `    return df\n`;
    prompt += `\`\`\`\n`;

    // CRITICAL: Add explicit completeness requirement
    prompt += `\n\n## ğŸ¯ CRITICAL COMPLETENESS REQUIREMENTS\n`;
    prompt += `âœ… MANDATORY: Generate a COMPLETE implementation with ALL methods:\n`;
    prompt += `   - __init__(): Full initialization with all parameters (MUST include worker info print)\n`;
    prompt += `   - get_trading_dates(): Get valid trading days using NYSE calendar\n`;
    prompt += `   - fetch_all_grouped_data(): Fetch ALL data using grouped endpoint (MUST show stage header)\n`;
    prompt += `   - _fetch_grouped_day(): Fetch one day's data (MUST use grouped endpoint URL)\n`;
    prompt += `   - compute_simple_features(): Compute basic features (price, volume, ADV)\n`;
    prompt += `   - apply_smart_filters(): Apply price/volume filters\n`;
    prompt += `   - compute_full_features(): Compute EMA, ATR, slopes\n`;
    prompt += `   - detect_patterns(): Scan for specific patterns\n`;
    prompt += `   - execute(): Main orchestration (MUST follow template above with stage headers)\n`;
    prompt += `   - run_and_save(): Execute and save to CSV\n`;
    prompt += `   - if __name__ == "__main__": CLI entry point with argparse\n`;
    prompt += `\nâš ï¸  CRITICAL PRINT FORMATTING REQUIREMENTS:\n`;
    prompt += `   âœ… __init__ MUST print: "ğŸš€ GROUPED ENDPOINT MODE: {Scanner} Scanner"\n`;
    prompt += `   âœ… __init__ MUST print: "ğŸ“… Signal Output Range (D0): {start} to {end}"\n`;
    prompt += `   âœ… __init__ MUST print: "ğŸ“Š Historical Data Range: {scan_start} to {scan_end}"\n`;
    prompt += `   âœ… __init__ MUST print: "âš¡ Workers: Stage1={N}, Stage3={M}"\n`;
    prompt += `   âœ… execute() MUST print: "ğŸš€ STAGE 1: FETCH GROUPED DATA" with separator lines\n`;
    prompt += `   âœ… execute() MUST print: "ğŸš€ STAGE 2: COMPUTE FEATURES + APPLY FILTERS" with separator\n`;
    prompt += `   âœ… execute() MUST print: "ğŸš€ STAGE 3: COMPUTE FULL FEATURES + SCAN PATTERNS" with separator\n`;
    prompt += `   âœ… execute() MUST print: "âœ… SCAN COMPLETE" with final signal count\n`;
    prompt += `   âœ… Use separator lines: print(f"\\n{'='*70}") before each major stage\n`;
    prompt += `\nâš ï¸  DO NOT truncate or omit any methods!\n`;
    prompt += `âš ï¸  DO NOT use "..." or "# implementation omitted" placeholders!\n`;
    prompt += `âš ï¸  EVERY method must have COMPLETE implementation!\n`;
    prompt += `âœ… Expected output: ~700-800 lines of complete Python code\n`;
    prompt += `âœ… Reference implementation: /projects/edge-dev-exact/templates/backside_b/fixed_formatted.py (716 lines)\n`;

    return prompt;
  }

  /**
   * Extract parameters from code
   */
  static extractParameters(code: string): Array<{name: string, value: any}> {
    const params: Array<{name: string, value: any}> = [];

    // Find P configuration block
    const pConfigMatch = code.match(/P\s*=\s*\{([^}]+)\}/);
    if (pConfigMatch) {
      const pConfigText = pConfigMatch[1];
      const paramLines = pConfigText.split('\n').filter(line => line.includes(':'));

      for (const line of paramLines) {
        const match = line.match(/"([^"]+)"\s*:\s*([^,}]+)/);
        if (match) {
          const value = match[2].trim();
          let parsedValue: string | number | boolean = value;

          if (value.includes('.') || !isNaN(parseFloat(value))) {
            parsedValue = parseFloat(value);
          } else if (value === 'True' || value === 'False' || value === 'true' || value === 'false') {
            parsedValue = value === 'True' || value === 'true';
          } else if (value.includes('"')) {
            parsedValue = value.replace(/"/g, '');
          }

          params.push({ name: match[1], value: parsedValue });
        }
      }
    }

    return params;
  }
}
